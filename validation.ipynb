{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cassandra\n",
    "import warnings\n",
    "import datetime\n",
    "import time\n",
    "import dask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as da\n",
    "from cassandra import ConsistencyLevel\n",
    "from cassandra.query import SimpleStatement\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "auth_provider1 = PlainTextAuthProvider(username='orderhub', password='/1234*')\n",
    "archival_cluster = Cluster(['u123kot'],port = 3176,auth_provider=auth_provider1)\n",
    "session = archival_cluster.connect('orders')\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "files = 1\n",
    "end_file = 8\n",
    "days_backup=100\n",
    "backup_date = 123173     #fixed\n",
    "cutoff_date = (backup_date - days_backup)\n",
    "directory= '/app/Python-docker/validation/'\n",
    "\n",
    "while (files <= end_file):\n",
    "        \n",
    "    try:\n",
    "        print(\"time started: \"+str(time.time()))\n",
    "        df_read_backup=da.read_csv(f'{directory}/partition/backup_data_{files}.csv')        \n",
    "        df_read_backup['julian_date'] = df_read_backup['order_id'].astype(str).str[1:6].astype(int)\n",
    "        df_read_backup['validated_list'] = cutoff_date > df_read_backup['julian_date']        \n",
    "               \n",
    "        order_list = list(df_read_backup.loc[df_read_backup['validated_list'] == True]['order_id'])\n",
    "    \n",
    "        order_str_list = ', '.join(f\"'{order}'\" for order in order_list)\n",
    "        \n",
    "        query1 = SimpleStatement(\"select count(1), order_id from orders.order_events where order_id in (%s) group by order_id\"%order_str_list,consistency_level=ConsistencyLevel.QUORUM)\n",
    "        query_result = session.execute(query1)                \n",
    "        \n",
    "        df_query_result = pd.DataFrame(query_result)\n",
    "    \n",
    "        df_query_result['order_id'] = df_query_result['order_id'].astype(np.int64)\n",
    "        df_query_result['count'] = df_query_result['count'].astype(int)     \n",
    "        df_combine = pd.merge(df_read_backup.compute(), df_query_result, how=\"left\", on=['order_id'])\n",
    "        \n",
    "        # #write in csv validation file\n",
    "        df_combine.loc[(df_combine['validated_list'] == True) & (df_combine['count'].notna())][['order_id','count']]\\\n",
    "            .to_csv(f'{directory}/validating/mark_validation_{files}.csv' , index = False)\n",
    "            \n",
    "        ##write non-validation file\n",
    "        df_combine.loc[df_combine['validated_list'] == False][['order_id']]\\\n",
    "            .to_csv(f'{directory}/validating/Not_validated_{files}.csv' , index = False)\n",
    "            \n",
    "        # #write error file\n",
    "        df_combine.loc[(df_combine['validated_list'] == True) & (df_combine['count'].isna())][['order_id']]\\\n",
    "            .to_csv(f'{directory}/errorlogfile/logfile_{files}.csv' , index = False)\n",
    "           \n",
    "      \n",
    "        print('No of completed files:',files) \n",
    "        files += 1\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print (e) \n",
    "        files += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
